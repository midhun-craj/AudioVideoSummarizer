{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPw0wd6M68O10p27FJuG/Mq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/midhun-craj/AudioVideoSummarizer/blob/main/AudioVideoSummarizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ucQcrnzEcMUl"
      },
      "outputs": [],
      "source": [
        "#@title Choose Model for Language Summarization(Audio)\n",
        "# @markdown BART : For better accuracy, but lenghty (FAST) \\\n",
        "# @markdown T-5  : Summary may be concise, but tends to Hallucinate (SLOW)\n",
        "# hdjdjd\n",
        "Model = \"BART\" # @param [\"BART\", \"T5\"]\n",
        "print(Model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive # loads a library to mount your google drive\n",
        "drive.mount('/content/drive')\n",
        "#!rm /content/drive/MyDrive/AVS/*\n",
        "#!rm -r /content/drive/MyDrive/AVS/Frames/*\n",
        "!mkdir /content/drive/MyDrive/AVS\n",
        "!mkdir /content/drive/MyDrive/AVS/preprocessed_img\n",
        "!mkdir /content/drive/MyDrive/AVS/summarized_frames\n",
        "!mkdir /content/drive/MyDrive/AVS/Frames\n",
        "!mkdir /content/drive/MyDrive/AVS/DATA"
      ],
      "metadata": {
        "id": "QsijjCoBcqlO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install numpy\n",
        "#!pip install tensorflow\n",
        "#!pip install keras\n",
        "#!pip install scikit-learn\n",
        "#!pip install matplotlib\n",
        "#!pip install scipy\n",
        "#!pip install tkinter\n",
        "#!pip install tqdm\n",
        "#!pip install seaborn\n",
        "#!pip install opencv-python\n",
        "#!pip install librosa\n",
        "#!pip install ffmpeg-python\n",
        "!pip install mutagen\n",
        "!pip install git+https://github.com/openai/whisper.git  # audio to text\n",
        "!sudo apt update && sudo apt install ffmpeg\n",
        "!pip install transformers                               # sumarization\n",
        "!pip install gTTS"
      ],
      "metadata": {
        "id": "AvvM0z6Mcty6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import math\n",
        "import imageio\n",
        "import cv2\n",
        "import random\n",
        "import pathlib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from imageio import imread, imsave\n",
        "from os.path import isfile, join\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tkinter import filedialog\n",
        "from os import listdir\n",
        "from mutagen.mp3 import MP3\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "from gtts import gTTS\n",
        "from IPython.display import Audio\n",
        "from moviepy import editor\n",
        "from transformers import pipeline, AutoModelForSeq2SeqLM, AutoTokenizer"
      ],
      "metadata": {
        "id": "AyG--bt6cwSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def FRAME_EXT(video_path, output_dir, interval=1):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(f\"Error: Could not find path'\")\n",
        "        return\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    frame_count = 0\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        if frame_count % interval == 0:\n",
        "            frame_path = os.path.join(output_dir, f\"frame_{frame_count}.jpg\")\n",
        "            cv2.imwrite(frame_path, frame)\n",
        "        frame_count += 1\n",
        "    cap.release()"
      ],
      "metadata": {
        "id": "UDn-HyJncy5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_directory = \"/content/drive/My Drive/AVS/DATA/\"\n",
        "Frame_directory = \"/content/drive/My Drive/AVS/Frames/\"\n",
        "\n",
        "# Get the list of files in the input directory and sort them by modification time\n",
        "videofiles = sorted(os.listdir(input_directory), key=lambda x: os.path.getmtime(os.path.join(input_directory, x)))\n",
        "i = 0\n",
        "for filename in videofiles:\n",
        "    if filename.endswith('.mp4'):\n",
        "       video_path = os.path.join(input_directory, filename)\n",
        "       FRAME_EXT(video_path, Frame_directory +str(filename), interval=30)\n",
        "       file_path = filename\n",
        "    i+=1\n",
        "print(\"Frame extraction is completed\")\n",
        " #preprocessing using bilateral filter\n",
        " #obtaining input image\n"
      ],
      "metadata": {
        "id": "6mhFgakvc1U-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(file_path,filename,input_directory+file_path)\n",
        "file_source = input_directory+file_path"
      ],
      "metadata": {
        "id": "bkvh_zGBc3Mq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessimg_path=\"/content/drive/My Drive/AVS/preprocessed_img/\"\n",
        "\n",
        "i = 0\n",
        "for filename1 in file_path:\n",
        "    from pathlib import Path\n",
        "    gg=Path(file_path).resolve().stem\n",
        "    video_path1 = os.path.join(Frame_directory, gg+str('.mp4'))\n",
        "    for filename in  listdir(video_path1):\n",
        "        video_path = os.path.join(video_path1,str(filename))\n",
        "        img = cv2.imread(video_path)\n",
        "        img = cv2.resize(img,[224,224])\n",
        "        # bilateral filter\n",
        "        filtered_img1  = cv2.bilateralFilter(img,9,75,75)\n",
        "\n",
        "        prefn = os.path.join(preprocessimg_path, filename)\n",
        "        cv2.imwrite(prefn, filtered_img1 )\n",
        "        mset1 = np.square(np.subtract(img,filtered_img1)).mean()\n",
        "        MSR1=np.mean(filtered_img1)/np.std(filtered_img1)\n",
        "        PSNRVAL2=10.0*math.log10((255*255)/mset1)\n",
        "        print('****** Bilateral filter results ****** ')\n",
        "        print(MSR1)\n",
        "        print(PSNRVAL2)\n",
        "    i+=1\n",
        "print(\"Pre processing is completed\")"
      ],
      "metadata": {
        "id": "bfWqBJH2c5st"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature extraction using DenseNet121 as the base model\n",
        "def load_data(dir_list, image_size):\n",
        "\n",
        "\n",
        "    # load all images in a directory\n",
        "    data = []\n",
        "    labl = []\n",
        "    image_width, image_height = image_size\n",
        "\n",
        "    base_model = DenseNet121(include_top=False,weights=None,classes = 2,input_tensor=None, input_shape=(224,224,3))\n",
        "    for directory in dir_list:\n",
        "        for filename in listdir(directory):\n",
        "            print(filename)\n",
        "            # load the image\n",
        "            path=directory  + filename\n",
        "            print(path)\n",
        "            image  = cv2.imread(path,3)\n",
        "            imgk = np.expand_dims(image, axis=0)\n",
        "            print(np.shape(image))\n",
        "            resincepfeat_par = base_model.predict(imgk)\n",
        "            print(np.shape(resincepfeat_par))\n",
        "            datak= np.array(resincepfeat_par)\n",
        "            datak= (np.mean(datak,1))\n",
        "            datak= (np.mean(datak,2))\n",
        "            datak1= (np.mean(datak))\n",
        "\n",
        "            if datak1 < 2:\n",
        "                labl.append([0])\n",
        "                data.append(datak)\n",
        "\n",
        "            elif datak1 > 2:\n",
        "                labl.append([1])\n",
        "                data.append(datak)\n",
        "\n",
        "    return data, labl,directory\n",
        "\n",
        "IMG_WIDTH, IMG_HEIGHT = (224,224)"
      ],
      "metadata": {
        "id": "GnulhOiRc81a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessimg_path=\"/content/drive/My Drive/AVS/preprocessed_img/\"\n",
        "print(listdir(preprocessimg_path))\n",
        "#model = tf.keras.models.load_model('model.h5')\n",
        "data, labl,directory = load_data([preprocessimg_path], (IMG_WIDTH, IMG_HEIGHT))\n",
        "labl = np.array(labl)\n",
        "data = np.array(data)\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional\n",
        "from keras.optimizers import SGD\n",
        "import math\n",
        "from sklearn.metrics import mean_squared_error\n",
        "AA=np.shape(data)\n",
        "model = Sequential()\n",
        "### First GRU layer with Dropout regularisation(Input)\n",
        "model.add(GRU(units=50, return_sequences=True, input_shape=(1, 7), activation='tanh'))\n",
        "model.add(Dropout(0.2))\n",
        "### Second GRU layer(Hidden)\n",
        "model.add(GRU(units=50, return_sequences=True, input_shape=(1, 7), activation='tanh'))\n",
        "model.add(Dropout(0.2))\n",
        "### Third GRU layer(Reset)\n",
        "model.add(GRU(units=50, return_sequences=True, input_shape=(1, 7), activation='tanh'))\n",
        "model.add(Dropout(0.2))\n",
        "### Fourth GRU layer(Update)\n",
        "model.add(GRU(units=50, activation='tanh'))\n",
        "model.add(Dropout(0.2))\n",
        "### The output layer\n",
        "model.add(Dense(units=1))\n",
        "import tensorflow as tf\n",
        "epochs = 50\n",
        "learning_rate = 0.01\n",
        "decay_rate = learning_rate / epochs\n",
        "optimizer = tf.keras.optimizers.legacy.Adam(lr=0.001,decay=decay_rate)\n",
        "#model.compile(optimizer=SGD(lr=0.001, decay=1e-7, momentum=0.9, nesterov=False),loss='mean_squared_error')\n",
        "model.compile(optimizer=optimizer,loss='mean_squared_error')\n",
        "### Fitting to the training set\n",
        "model.fit(data,labl,epochs=50,batch_size=150)\n",
        "out = model.predict(data)\n",
        "### The LSTM architecture\n",
        "model1 = Sequential()\n",
        "### First LSTM layer with Dropout regularisation\n",
        "model1.add(LSTM(units=50, return_sequences=True, input_shape=(1,7)))\n",
        "model1.add(Dropout(0.2))\n",
        "### Second LSTM layer\n",
        "model1.add(LSTM(units=50, return_sequences=True))\n",
        "model1.add(Dropout(0.2))\n",
        "### Third LSTM layer\n",
        "model1.add(LSTM(units=50, return_sequences=True))\n",
        "model1.add(Dropout(0.2))\n",
        "### Fourth LSTM layer\n",
        "model1.add(LSTM(units=50))\n",
        "model1.add(Dropout(0.2))\n",
        "### The output layer\n",
        "model1.add(Dense(units=1))\n",
        "model1.compile(optimizer='rmsprop',loss='mean_squared_error')\n",
        "### Fitting to the training set\n",
        "model1.fit(data,labl,epochs=50,batch_size=32)\n",
        "out1 = model1.predict(data)\n",
        "\n",
        "out=np.round(out*1000)\n",
        "out1=np.round(out1*1000)\n",
        "aa=np.shape(out)\n",
        "flab=np.zeros([aa[0],1], dtype=int)\n",
        "##\n",
        "for ip in range(0,aa[0]):\n",
        "    if [out[ip]]==out1[ip]:\n",
        "        flab[ip]=out[ip]\n",
        "    else:\n",
        "        flab[ip]=out1[ip]\n",
        "##\n",
        "list=np.unique(flab, return_index=True)\n",
        "index=list[1]\n",
        "index=np.sort(index)\n",
        "print(index)\n",
        "#print(\"Accuracy:\",metrics.accuracy_score(c1, c))"
      ],
      "metadata": {
        "id": "4zMUBjvPc_52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(list)"
      ],
      "metadata": {
        "id": "AyAsPDOudB7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# summarized frames\n",
        "\n",
        "preprocessimg_path=\"/content/drive/My Drive/AVS/preprocessed_img/\"\n",
        "summarizedimg_path=\"/content/drive/My Drive/AVS/summarized_frames/\"\n",
        "fn=29\n",
        "for filename in  index:\n",
        "\n",
        "  #print(fn)\n",
        "  video_path = preprocessimg_path+'frame_'+str(filename+filename*fn)+'.jpg'\n",
        "  #fn=fn+29\n",
        "  print(filename+fn)\n",
        "  print(video_path)\n",
        "  img = cv2.imread(video_path)\n",
        "  prefn = summarizedimg_path+str(filename)+'.jpg'\n",
        "  cv2.imwrite(prefn, img )\n",
        "print(\"Video Summarization is completed\")"
      ],
      "metadata": {
        "id": "ei72ssmRdEMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/whisper.git  # audio to text\n",
        "!sudo apt update && sudo apt install ffmpeg\n",
        "!pip install transformers                               # sumarization\n",
        "!pip install gTTS"
      ],
      "metadata": {
        "id": "7lZD8UYRdGHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!echo $file_source"
      ],
      "metadata": {
        "id": "VTTEqx8pdHxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp \"$file_source\" videoIn.mp4"
      ],
      "metadata": {
        "id": "JCwEUPdHdLfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!whisper videoIn.mp4 --model medium --language English"
      ],
      "metadata": {
        "id": "Xlg9zatwdNOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_directory = \"/content/videoIn.txt\"\n",
        "#input_directory = \"/content/7.txt\"\n",
        "file = open(input_directory,'r')\n",
        "my_text = file.read()\n",
        "print(my_text)\n",
        "file.close()\n",
        "wordCount = len(my_text.split())\n",
        "sumMax = wordCount - wordCount//10\n",
        "sumMin = wordCount//2\n",
        "print(wordCount,sumMax,sumMin)"
      ],
      "metadata": {
        "id": "XgexK2MFdO2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if Model == \"BART\":\n",
        "  summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "  summary = summarizer(my_text, max_length=sumMax, min_length=sumMin, do_sample=False)\n",
        "  summaryText = summary[0]['summary_text']\n",
        "  print(\"BART : \", summary[0]['summary_text'])\n",
        "else:\n",
        "  my_text = \"summarise : \" + my_text\n",
        "  model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-large\")\n",
        "  tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-large\")\n",
        "  inputs = tokenizer(my_text, return_tensors=\"pt\")\n",
        "  outputs = model.generate(**inputs, \\\n",
        "                        min_length=20, \\\n",
        "                        max_new_tokens=512, \\\n",
        "                        length_penalty = 2, \\\n",
        "                        num_beams=16, \\\n",
        "                        temperature=0.9, \\\n",
        "                        no_repeat_ngram_size=2, \\\n",
        "                        #num_return_sequences 2,\\\n",
        "                        early_stopping=True)\n",
        "  output_text_Flan_t5 = tokenizer.batch_decode(outputs, \\\n",
        "                                               skip_special_tokens=True)\n",
        "  summaryText = str(output_text_Flan_t5)\n",
        "  print (\"T5 : \",summaryText)"
      ],
      "metadata": {
        "id": "dPfYZehidREr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sumCount = len(summaryText.split())\n",
        "print(sumCount)"
      ],
      "metadata": {
        "id": "e8nEowJGdS6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = open(\"summary.txt\",'w')\n",
        "#file.writelines(summary[0]['summary_text'])\n",
        "file.writelines(summaryText)\n",
        "file.close()"
      ],
      "metadata": {
        "id": "NLXSTN2pdUpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tts = gTTS(summary[0]['summary_text'])\n",
        "tts = gTTS(summaryText)\n",
        "sound_file = \"/content/drive/My Drive/out.mp3\"\n",
        "tts.save(sound_file)\n",
        "\n",
        "Audio(sound_file, autoplay=False)"
      ],
      "metadata": {
        "id": "KY5JBprcdWfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summarizedimg_path = \"/content/drive/MyDrive/AVS/summarized_frames\""
      ],
      "metadata": {
        "id": "1lCcQ3bPdYql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fusion\n",
        "\n",
        "\n",
        "video_path = input_directory\n",
        "images_path = summarizedimg_path\n",
        "audio_path = \"/content/drive/My Drive/out.mp3\"\n",
        "audio = MP3(audio_path)\n",
        "audio_length = audio.info.length\n",
        "list_of_images = []\n",
        "for image_file in os.listdir(images_path):\n",
        "    if image_file.endswith('.png') or image_file.endswith('.jpg'):\n",
        "        image_path = os.path.join(images_path, image_file)\n",
        "        image = Image.open(image_path).resize((400, 400), Image.ANTIALIAS)\n",
        "        list_of_images.append(image)\n",
        "print(audio_length)\n",
        "duration = audio_length/len(list_of_images)\n",
        "print(duration)\n",
        "imageio.mimsave('images.gif', list_of_images, fps=1/duration)\n",
        "\n",
        "video = editor.VideoFileClip(\"images.gif\")\n",
        "audio = editor.AudioFileClip(audio_path)\n",
        "final_video = video.set_audio(audio)\n",
        "os.chdir(\"/content/drive/My Drive/AVS/\")\n",
        "final_video.write_videofile(fps=1/duration, codec=\"libx264\", filename=\"videok.mp4\")"
      ],
      "metadata": {
        "id": "G-Dl6iMAda7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title -\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "mp4 = open('/content/drive/My Drive/AVS/videok.mp4','rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width=650 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ],
      "metadata": {
        "id": "Q_eWyFMrddAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!rm -r /content/drive/MyDrive/AVS/preprocessed_img/*\n",
        "#!rm -r /content/drive/MyDrive/AVS/summarized_frames/*\n",
        "#!rm -r /content/drive/MyDrive/AVS/Frames/*\n",
        "#!rm -r /content/drive/MyDrive/AVS/DATA/*"
      ],
      "metadata": {
        "id": "K4NFVR_QderL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!rm /content/drive/MyDrive/AVS/*\n",
        "#!rm -r /content/drive/MyDrive/AVS/Frames/*"
      ],
      "metadata": {
        "id": "9yeVG30fdgB8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}